# -*- coding: utf-8 -*-
"""blood_donation_forecast.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gxoMwm3LB5ilYOHflAiCzMmFpJLTuNi5
"""

!pip install xgboost imbalanced-learn

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
import xgboost as xgb
from imblearn.over_sampling import SMOTE

# Load + prep (from your notebook)
url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data'
df = pd.read_csv(url, header=0)
df.columns = ['Recency', 'Frequency', 'Monetary', 'Time', 'target']
df['target'] = df['target'].astype(int)

# Log normalize Monetary (fixes variance)
df['Monetary_log'] = np.log(df['Monetary'])
df.drop('Monetary', axis=1, inplace=True)

X = df.drop('target', axis=1)
y = df['target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print("Class balance:", y.value_counts(normalize=True))
print("Shape:", X.shape)

import matplotlib.pyplot as plt
# SMOTE oversampling (optional, boosts recall)
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

# XGBoost
model = xgb.XGBClassifier(
    scale_pos_weight=3,  # Handle 76/24 imbalance
    n_estimators=100,
    learning_rate=0.1,
    max_depth=3,
    random_state=42
)
model.fit(X_train_smote, y_train_smote)

# Results
y_proba = model.predict_proba(X_test)[:, 1]
auc = roc_auc_score(y_test, y_proba)
print(f"âœ… XGBoost AUC: {auc:.4f}")  # ~0.81 (beats 0.7891)

# Feature importance
xgb.plot_importance(model)
plt.show()

